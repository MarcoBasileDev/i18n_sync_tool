import eel
import os
import re
import json

# Initialize Eel -> 'web' folder
eel.init('web')

INPUT_DIR = "input"
OUTPUT_DIR = "output"

def extract_data(file_path):
    """
    Extracts KEY: VALUE pairs from both JSON and JS/TS files.
    """
    data_map = {}
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()

        try:
            # Try parsing as JSON
            return json.loads(content)
        except json.JSONDecodeError:
            # Advanced regex to capture KEY: 'Value' (multiline supported)
            # Supports both single and double quotes
            pattern = r'([A-Z][A-Z0-9_]+)\s*:\s*(?P<quote>[\'"])(.*?)(?P=quote)'
            matches = re.finditer(pattern, content, re.DOTALL)
            for match in matches:
                key = match.group(1)
                value = match.group(3).strip()
                data_map[key] = value
            return data_map

def save_missing_for_llm(source_file_name, source_data, target_file_name, target_keys):
    """
    Creates a file containing missing keys in the original format
    to facilitate translation via an LLM.
    """
    missing_keys = set(source_data.keys()) - target_keys
    if not missing_keys:
        return None

    output_filename = os.path.join(
        OUTPUT_DIR,
        f"missing_in_{target_file_name}.txt"
    )

    with open(output_filename, 'w', encoding='utf-8') as f:
        f.write(
            f"// MISSING KEYS IN {target_file_name}\n"
            f"// Source file: {source_file_name}\n"
            f"// Generated by localization sync tool\n\n"
        )

        for key in sorted(missing_keys):
            # Preserve the original KEY: 'Value', structure
            f.write(f"  {key}: '{source_data[key]}',\n")

    return output_filename

def main():
    extensions = ('.json', '.js', '.ts')
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    files = [
        f for f in os.listdir(INPUT_DIR)
        if f.endswith(extensions)
    ]

    if len(files) < 2:
        print("At least 2 files are required to perform a comparison.")
        return

    # 1. Load data
    all_data = {
        file: extract_data(os.path.join(INPUT_DIR, file))
        for file in files
    }

    # 2. Select source file
    print("\nFiles found:")
    for index, file in enumerate(files):
        print(f"[{index}] {file}")

    source_index = int(input("\nEnter the SOURCE file number: "))
    source_file = files[source_index]
    source_data = all_data[source_file]

    # 3. Analysis and output
    print(f"\n--- Analysis relative to: {source_file} ---")

    for target_file in files:
        if target_file == source_file:
            continue

        target_data = all_data[target_file]
        target_keys = set(target_data.keys())

        # Quick summary
        common_keys = set(source_data.keys()).intersection(target_keys)
        missing_keys = set(source_data.keys()) - target_keys

        print(f"\n> Analyzing {target_file}:")
        print(f"  - Common keys: {len(common_keys)}")
        print(f"  - Missing keys: {len(missing_keys)}")

        if missing_keys:
            output_name = save_missing_for_llm(
                source_file,
                source_data,
                target_file,
                target_keys
            )
            print(f"  [!] Translation helper file created: {output_name}")
        else:
            print("  [OK] File already synchronized.")

if __name__ == "__main__":
    main()
